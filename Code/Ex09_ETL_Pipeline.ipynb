{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tutorial 9: Extracting and Transforming Data**\n",
    "\n",
    "In this tutorial, we will walk through the process of **extracting** and **transforming** data from a SQL database using Python. We will:\n",
    "- Connect to a SQL Server database using `SQLAlchemy` and `pyodbc`\n",
    "- Extract data from the **Sales.Orders** table\n",
    "- Transform the data to filter only **date-related columns**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Install Required Libraries**\n",
    "Before starting, ensure you have the required Python libraries installed. If not, install them using:\n",
    "\n",
    "```bash\n",
    "pip install pandas sqlalchemy pyodbc\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Import Required Libraries**\n",
    "We begin by importing the necessary libraries:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Define the Database Connection**\n",
    "We use **SQLAlchemy** to create a connection string for a Microsoft SQL Server database.\n",
    "\n",
    "```python\n",
    "# Define the ODBC connection parameters\n",
    "driver = 'ODBC Driver 18 for SQL Server' \n",
    "\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{{driver}}};SERVER={server};DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password};ENCRYPT=yes;TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "```\n",
    "\n",
    "Replace:\n",
    "- **`your_server`** with the actual SQL Server name.\n",
    "- **`your_database`** with your database name.\n",
    "- **`your_username`** and **`your_password`** with your credentials.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "server = os.getenv(\"DB_SERVER\")\n",
    "database = os.getenv(\"DB_NAME\")\n",
    "username = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\") \n",
    "driver = 'ODBC Driver 18 for SQL Server' \n",
    "\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{{driver}}};SERVER={server};DATABASE={database};\"\n",
    "    f\"UID={username};PWD={password};ENCRYPT=yes;TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "query = \"\"\" \n",
    "    SELECT * FROM Sales.Orders;\n",
    "    \"\"\"\n",
    "\n",
    "raw_data = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4: Extract Data from SQL Database**\n",
    "### **Explanation:**\n",
    "- The `extract()` function executes an SQL query to retrieve all columns from the **Sales.Orders** table.\n",
    "- `pd.read_sql()` fetches the query results into a **pandas DataFrame**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract(engine):\n",
    "    query = \"\"\" \n",
    "        SELECT * FROM Sales.Orders;\n",
    "    \"\"\"\n",
    "    raw_data = pd.read_sql(query, engine)\n",
    "\n",
    "    return raw_data\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "raw_sales_data  = extract(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5: Transform the Data**\n",
    "Define a function that filters the dataset by keeping only columns that **do not contain null values**. Ensure that **date-related columns** are properly formatted as **datetime** objects.\n",
    "\n",
    "```python\n",
    "Example codes: \n",
    "# Extract Columns that do not have null values\n",
    "no_null_columns = raw_data.columns[~raw_data.isnull().any()].to_list()\n",
    "clean_data = raw_data[no_null_columns]\n",
    "# Convert date-related columns to datetime if applicable\n",
    "clean_data[col] = pd.to_datetime(clean_data[col])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the transform function to return the columns that includes the date data. \n",
    "def transform(raw_data):\n",
    "  \t# Edit the below codes to Filter rows and columns\n",
    "    clean_data = raw_data.copy()\n",
    "    \n",
    "    return clean_data\n",
    "\n",
    "clean_data = transform(raw_sales_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Expected Output**\n",
    "\n",
    "| OrderID | CustomerID | SalespersonPersonID | ContactPersonID | OrderDate  | ExpectedDeliveryDate | CustomerPurchaseOrderNumber | IsUndersupplyBackordered | LastEditedBy | LastEditedWhen         |\n",
    "|---------|-----------|---------------------|-----------------|------------|----------------------|----------------------------|--------------------------|--------------|------------------------|\n",
    "| 1       | 832       | 2                   | 3032            | 2013-01-01 | 2013-01-02          | 12126                      | True                     | 7            | 2013-01-01 12:00:00    |\n",
    "| 2       | 803       | 8                   | 3003            | 2013-01-01 | 2013-01-02          | 15342                      | True                     | 7            | 2013-01-01 12:00:00    |\n",
    "| 3       | 105       | 7                   | 1209            | 2013-01-01 | 2013-01-02          | 12211                      | True                     | 7            | 2013-01-01 12:00:00    |\n",
    "| 4       | 57        | 16                  | 1113            | 2013-01-01 | 2013-01-02          | 17129                      | True                     | 3            | 2013-01-01 11:00:00    |\n",
    "| 5       | 905       | 3                   | 3105            | 2013-01-01 | 2013-01-02          | 10369                      | True                     | 7            | 2013-01-01 12:00:00    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>SalespersonPersonID</th>\n",
       "      <th>PickedByPersonID</th>\n",
       "      <th>ContactPersonID</th>\n",
       "      <th>BackorderOrderID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ExpectedDeliveryDate</th>\n",
       "      <th>CustomerPurchaseOrderNumber</th>\n",
       "      <th>IsUndersupplyBackordered</th>\n",
       "      <th>Comments</th>\n",
       "      <th>DeliveryInstructions</th>\n",
       "      <th>InternalComments</th>\n",
       "      <th>PickingCompletedWhen</th>\n",
       "      <th>LastEditedBy</th>\n",
       "      <th>LastEditedWhen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>832</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3032</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>12126</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>803</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3003</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>15342</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1209</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>12211</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>17129</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-01-01 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>905</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3105</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>10369</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderID  CustomerID  SalespersonPersonID  PickedByPersonID  \\\n",
       "0        1         832                    2               NaN   \n",
       "1        2         803                    8               NaN   \n",
       "2        3         105                    7               NaN   \n",
       "3        4          57                   16               3.0   \n",
       "4        5         905                    3               NaN   \n",
       "\n",
       "   ContactPersonID  BackorderOrderID   OrderDate ExpectedDeliveryDate  \\\n",
       "0             3032              45.0  2013-01-01           2013-01-02   \n",
       "1             3003              46.0  2013-01-01           2013-01-02   \n",
       "2             1209              47.0  2013-01-01           2013-01-02   \n",
       "3             1113               NaN  2013-01-01           2013-01-02   \n",
       "4             3105              48.0  2013-01-01           2013-01-02   \n",
       "\n",
       "  CustomerPurchaseOrderNumber  IsUndersupplyBackordered Comments  \\\n",
       "0                       12126                      True     None   \n",
       "1                       15342                      True     None   \n",
       "2                       12211                      True     None   \n",
       "3                       17129                      True     None   \n",
       "4                       10369                      True     None   \n",
       "\n",
       "  DeliveryInstructions InternalComments PickingCompletedWhen  LastEditedBy  \\\n",
       "0                 None             None  2013-01-01 12:00:00             7   \n",
       "1                 None             None  2013-01-01 12:00:00             7   \n",
       "2                 None             None  2013-01-01 12:00:00             7   \n",
       "3                 None             None  2013-01-01 11:00:00             3   \n",
       "4                 None             None  2013-01-01 12:00:00             7   \n",
       "\n",
       "       LastEditedWhen  \n",
       "0 2013-01-01 12:00:00  \n",
       "1 2013-01-01 12:00:00  \n",
       "2 2013-01-01 12:00:00  \n",
       "3 2013-01-01 11:00:00  \n",
       "4 2013-01-01 12:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract raw data from the database\n",
    "raw_sales_data = extract(engine)\n",
    "\n",
    "# Transform the raw data to include only date/time columns\n",
    "clean_sales_data = transform(raw_sales_data)\n",
    "\n",
    "# Display the transformed data\n",
    "display(clean_sales_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7: Load the Data**\n",
    "After transforming the data, save it to a CSV file for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to ./data/processed/clean_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output file path\n",
    "output_path = \"./data/processed/clean_sales_data.csv\"\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "clean_sales_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache **Parquet** is a columnar storage format that is optimized for big data processing. Unlike traditional row-based formats (such as CSV), Parquet stores data by columns, making it more efficient for analytical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to ./data/processed/clean_sales_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define the output file path\n",
    "output_path = \"./data/processed/clean_sales_data.parquet\"\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "clean_sales_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
